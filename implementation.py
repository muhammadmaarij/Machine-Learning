#search dataset
#kaggle
#uci
#QuandL
# file path
# or generate ourselves
# multiple files dataset -> concat and make single file

# freq of data generation (updation)
# instances features
# kahan ka ha
# size of file


#Main steps to run classifier
#1. Gather data
#2. Import Lib numpy(array), pandas(data analysis), Scikit-learn(classifiers)
#3. Preprocessing(for accuracy) feature scaling
# clean
# outlier remove
# balancing

#4. Feature engineering Dim reduction
#5. Split data on train and test 80 20
#6. Build model like knn and fit and tune hyperparameters to optimize
#7. Evaluate presision, accuracy, recall (True negative etc), F1-score (harmonic mean)
#8. Improve the model
#9. Deploy the model


# from google.colab import drive     dataset stored on drive
# drive.mount('/content/drive)
# import pandas as pd
# 

# DH.shape

#KNN implementation
#standard scaling for plotting
#splitting in dependent and independent x, y
# iloc: select rows and cols 
# drop: does same but with col name
#random_state= 42  code reproduction time maintain accuracy
#test train predict
#ture + true - 
#
#
#
#
#
#